{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path= r\"C:\\Users\\USER\\Desktop\\사용할만한 csv파일\\2008년 남자데이터 (결측치 대치,k=5).CSV\"\n",
    "X=pd.read_csv(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "종속변수 (Y), 독립변수 (X) 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "컬럼 개수 : 88\n"
     ]
    }
   ],
   "source": [
    "Y=X['fat']\n",
    "X=X.drop(['fat', 'DW_WBT_pFT'], axis=1)    #얻을 수 없는 column제거\n",
    "print(\"컬럼 개수 :\", len(X.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training set, test set 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체특성으로 훈련시킨 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 1 테스트 세트 정확도 (모든 특성): 0.5270900609974883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "\n",
    "# 모델 생성\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "print(\"모델 1 테스트 세트 정확도 (모든 특성):\", accuracy)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter approach로 feature selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 교차검정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of features: 42\n",
      "Best score (MAE): 0.5751233962041035\n",
      "Selected features: ['DK9_dg', 'DE1_dg', 'BS5_21', 'L_DN_FAM', 'sex', 'LK_LB_IT', 'BS9_2', 'EC_wht_5', 'occp', 'LQ_4EQL', 'BE5_1', 'DI2_dg', 'BO3_07', 'N_FAT', 'DC6_dg', 'BP8', 'BH1', 'BO3_01', 'LQ4_00', 'L_OUT_FQ', 'BO3_05', 'LQ_5EQL', 'DC1_dg', 'pa_walk', 'DE1_32', 'LK_EDU', 'EC_lgw_2', 'sm_presnt', 'BO3_09', 'BS3_1', 'BMI', 'BS8_2', 'genertn', 'BD1_11', 'ho_incm5', 'BP1', 'pa_mid', 'N_PROT', 'DJ4_3', 'HE_ht', 'BO3_12', 'allownc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "max_features = X_train.shape[1]  # 데이터의 전체 특성 개수\n",
    "feature_range = range(1, max_features+1)\n",
    "\n",
    "best_score = float('inf')  # 초기값을 무한대로 설정\n",
    "best_num_features = 0\n",
    "best_selected_features = None\n",
    "\n",
    "for num_features in feature_range:\n",
    "    # 모델 생성\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    feature_names = X_train.columns.tolist()\n",
    "    # 특정 개수의 특성 선택\n",
    "    selected_features = feature_names[:num_features]  # 선택된 특성의 이름 또는 인덱스\n",
    "    \n",
    "    # 선택된 특성만으로 데이터 준비\n",
    "    X_selected_train = X_train[selected_features]\n",
    "    \n",
    "    # 교차 검증 수행\n",
    "    scores = cross_val_score(model, X_selected_train, Y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "    \n",
    "    # 평균 성능 계산 (음수로 저장되어 있으므로 양수로 변환)\n",
    "    mean_score = -scores.mean()\n",
    "    \n",
    "    # 최적의 특성 개수 및 성능 갱신\n",
    "    if num_features == 1 or mean_score < best_score:\n",
    "        best_score = mean_score\n",
    "        best_num_features = num_features\n",
    "        best_selected_features = selected_features\n",
    "\n",
    "print(\"Best number of features:\", best_num_features)\n",
    "print(\"Best score (MAE):\", best_score)\n",
    "print(\"Selected features:\", best_selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5270900609974883\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 특성 선택\n",
    "selected_features_order =  selected_features\n",
    "# 선택된 특성으로 데이터 준비\n",
    "X_selected = X_train.loc[:, selected_features_order]  # 수정된 코드\n",
    "Y_selected = Y_train\n",
    "\n",
    "# 의사결정 트리 모델 생성\n",
    "model2 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model2.fit(X_selected, Y_selected)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "X_test_selected = X_test.loc[:, selected_features_order]  # 수정된 코드\n",
    "Y_pred = model2.predict(X_test_selected)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분산 기반 filter approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected features: 84\n",
      "Selected features: ['DE1_dg', 'BS5_21', 'L_DN_FAM', 'sex', 'LK_LB_IT', 'BS9_2', 'EC_wht_5', 'occp', 'LQ_4EQL', 'BE5_1', 'DI2_dg', 'BO3_07', 'N_FAT', 'BP8', 'BH1', 'BO3_01', 'LQ4_00', 'L_OUT_FQ', 'BO3_05', 'LQ_5EQL', 'DC1_dg', 'pa_walk', 'DE1_32', 'LK_EDU', 'EC_lgw_2', 'sm_presnt', 'BO3_09', 'BS3_1', 'BMI', 'BS8_2', 'genertn', 'BD1_11', 'ho_incm5', 'BP1', 'pa_mid', 'N_PROT', 'DJ4_3', 'HE_ht', 'BO3_12', 'allownc', 'DK8_dg', 'DC5_dg', 'BD2_1', 'DI3_dg', 'BO3_03', 'DI1_2', 'DI2_2', 'BO3_04', 'N_WATER', 'L_BR_FAM', 'DJ4_dg', 'DI4_dg', 'DI1_dg', 'HE_wc', 'LQ_3EQL', 'N_EN', 'BO2_1', 'DN1_dg', 'DE2_dg', 'BO1_3', 'N_DIET', 'LQ_1EQL', 'N_CHO', 'DL1_dg', 'HE_wt', 'EC1_1', 'DF2_dg', 'DM1_dg', 'L_LN_FAM', 'incm5', 'edu', 'DC4_dg', 'D_1_1', 'LF_SAFE', 'house', 'EC_occp', 'N_INTK', 'marri_1', 'age', 'DC3_dg', 'BO3_02', 'DK4_dg', 'BS5_22', 'BO1_1']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 특성 선택 기준 설정\n",
    "threshold = 0.1  # 분산 기준값\n",
    "\n",
    "# 분산 기반의 특성 선택 수행\n",
    "selector = VarianceThreshold(threshold=threshold)\n",
    "X_selected = selector.fit_transform(X_train)\n",
    "\n",
    "# 선택된 특성 개수 출력\n",
    "num_selected_features = X_selected.shape[1]\n",
    "print(\"Number of selected features:\", num_selected_features)\n",
    "\n",
    "# 선택된 특성 인덱스 가져오기\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "# 선택된 특성 이름 가져오기\n",
    "selected_feature_names = X.columns[selected_feature_indices]\n",
    "\n",
    "# 선택된 특성 출력\n",
    "print(\"Selected features:\", selected_feature_names.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5249372084678866\n"
     ]
    }
   ],
   "source": [
    "# 특성 선택\n",
    "selected_features_order =  selected_feature_names\n",
    "\n",
    "# 선택된 특성으로 데이터 준비\n",
    "X_selected = X_train.loc[:, selected_features_order]  # 수정된 코드\n",
    "Y_selected = Y_train\n",
    "\n",
    "# 의사결정 트리 모델 생성\n",
    "model2 = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# 모델 학습\n",
    "model2.fit(X_selected, Y_selected)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "X_test_selected = X_test.loc[:, selected_features_order]  # 수정된 코드\n",
    "Y_pred = model2.predict(X_test_selected)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrapper approach (forward)\n",
    "\n",
    "sfs 알고리즘 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_sequential.py:211: FutureWarning: Leaving `n_features_to_select` to None is deprecated in 1.0 and will become 'auto' in 1.3. To keep the same behaviour as with None (i.e. select half of the features) and avoid this warning, you should manually set `n_features_to_select='auto'` and set tol=None when creating an instance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.5385719411553642\n",
      "Selected features: ['DK9_dg', 'DE1_dg', 'L_DN_FAM', 'sex', 'EC_wht_5', 'BO3_07', 'DC6_dg', 'L_OUT_FQ', 'BO3_05', 'DC1_dg', 'DE1_32', 'LK_EDU', 'EC_lgw_2', 'BO3_09', 'BMI', 'DJ4_3', 'BO3_12', 'allownc', 'DK8_dg', 'DC5_dg', 'DI3_dg', 'DI1_2', 'BO3_04', 'L_BR_FAM', 'DJ4_dg', 'DI4_dg', 'DI1_dg', 'HE_wc', 'LQ_3EQL', 'BO2_1', 'DN1_dg', 'DE2_dg', 'BO1_3', 'LQ_1EQL', 'DC2_dg', 'DL1_dg', 'HE_wt', 'EC1_1', 'DF2_dg', 'DC4_dg', 'DC3_dg', 'LQ_2EQL', 'BO3_02', 'DK4_dg']\n",
      "Number of selected features: 44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# 의사결정 트리 모델 생성\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# SequentialFeatureSelector 객체 생성\n",
    "sfs = SequentialFeatureSelector(estimator=model, direction='forward')\n",
    "\n",
    "# 특성 선택 수행\n",
    "X_selected = sfs.fit_transform(X_train, Y_train)\n",
    "\n",
    "# 의사결정 트리 모델 학습\n",
    "model.fit(X_selected, Y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "X_test_selected = sfs.transform(X_test)\n",
    "Y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "# 선택된 특성\n",
    "selected_feature_names = [feature for feature, selected in zip(X.columns, sfs.get_support()) if selected]\n",
    "\n",
    "# 선택된 특성 개수\n",
    "num_selected_features = len(selected_feature_names)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Best accuracy:\", accuracy)\n",
    "print(\"Selected features:\", selected_feature_names)\n",
    "print(\"Number of selected features:\", num_selected_features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wrapper approach (backward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.5242195909580194\n",
      "Selected features: Index(['BS5_21', 'L_DN_FAM', 'LK_LB_IT', 'BS9_2', 'EC_wht_5', 'occp',\n",
      "       'LQ_4EQL', 'BE5_1', 'N_FAT', 'BP8', 'L_OUT_FQ', 'pa_walk', 'EC_lgw_2',\n",
      "       'BS3_1', 'BMI', 'BS8_2', 'genertn', 'BD1_11', 'ho_incm5', 'BP1',\n",
      "       'N_PROT', 'HE_ht', 'BD2_1', 'BO3_03', 'DI1_2', 'N_WATER', 'L_BR_FAM',\n",
      "       'HE_wc', 'N_EN', 'BO2_1', 'N_CHO', 'HE_wt', 'DF2_dg', 'DM1_dg',\n",
      "       'L_LN_FAM', 'incm5', 'edu', 'D_1_1', 'LF_SAFE', 'house', 'EC_occp',\n",
      "       'N_INTK', 'age', 'BO1_1'],\n",
      "      dtype='object')\n",
      "Selected feature count: 44\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "# 특성 개수 자동 선택\n",
    "rfe = RFE(estimator=model, step=1)\n",
    "rfe.fit(X_train, Y_train)\n",
    "\n",
    "# 훈련 데이터에 대한 예측 값\n",
    "X_selected = rfe.transform(X_train)\n",
    "model.fit(X_selected, Y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 값\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "Y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "# 선택된 특성\n",
    "selected_feature_names = X.columns[rfe.support_]\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Best accuracy:\", accuracy)\n",
    "print(\"Selected features:\", selected_feature_names)\n",
    "selected_feature_count = len(selected_feature_names)\n",
    "print(\"Selected feature count:\", selected_feature_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
